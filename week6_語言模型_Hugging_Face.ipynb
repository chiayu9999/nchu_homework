{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwcN41PQf73W"
      },
      "source": [
        "# <b>Hugging Face</b>\n",
        "Hugging Face 網址：https://huggingface.co/\n",
        "\n",
        "Hugging Face 是 AI 領域的開放平台，像 GitHub 一樣託管並分享 AI 模型與資料集。也收錄了很多來自頂尖研究的模型，涵蓋 NLP、計算機視覺、語音處理等領域。使用者可以在 Hub 上存取、分享、微調模型，加速 AI 的合作與創新。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm3BPUPx4CSE",
        "outputId": "270a386b-0887-428c-d40f-b629d9e2fbc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "- datasets 是 Hugging Face 提供的資料集載入工具\n",
        "- 它整合了數千個公開資料集，包含 NLP、CV、Audio 等領域\n",
        "- 提供統一的介面來下載、處理和使用資料集\n",
        "- 支援快取機制，避免重複下載\n",
        "\"\"\"\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbAzKp4WM4O9"
      },
      "source": [
        "### <b>資料前處理</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vr2un8u4CSF",
        "outputId": "811f0f15-8edc-494c-eae6-1e0fb8aa5786",
        "colab": {
          "referenced_widgets": [
            "241edb7cad16424daedfc47682fa2e51",
            "9282ca6790ef4274924661c3b455c4a7",
            "31b04ac53e894848a0ab4381b19b53b7",
            "64b645aaa64d4b36ba5a3b2c7eb1af02",
            "442a8e90722c43d9babb54319ca28e1e",
            "31f460e49c854ec1bc1bee067bbbb003"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "241edb7cad16424daedfc47682fa2e51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9282ca6790ef4274924661c3b455c4a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "dataset_infos.json:   0%|          | 0.00/800 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31b04ac53e894848a0ab4381b19b53b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/327k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64b645aaa64d4b36ba5a3b2c7eb1af02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/test-00000-of-00001.parquet:   0%|          | 0.00/80.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "442a8e90722c43d9babb54319ca28e1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/3877 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31f460e49c854ec1bc1bee067bbbb003",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/969 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['sentence', 'label'],\n",
            "        num_rows: 3877\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['sentence', 'label'],\n",
            "        num_rows: 969\n",
            "    })\n",
            "})\n",
            "訓練集： Dataset({\n",
            "    features: ['sentence', 'label'],\n",
            "    num_rows: 3877\n",
            "})\n",
            "測試集： Dataset({\n",
            "    features: ['sentence', 'label'],\n",
            "    num_rows: 969\n",
            "})\n",
            "訓練集欄位： ['sentence', 'label']\n",
            "測試集欄位： ['sentence', 'label']\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "\"\"\"\n",
        "為什麼選擇 auditor_sentiment 資料集？\n",
        "1. 金融領域專業性：專門針對財務報告和審計意見設計\n",
        "2. 標籤品質：由金融專家標註，確保情緒分類的準確性\n",
        "3. 真實場景：模擬實際金融分析師的工作情境\n",
        "4. 三分類問題：Negative(負面)、Neutral(中性)、Positive(正面)\n",
        "\n",
        "這個資料集適合用來訓練金融新聞情緒分析模型，\n",
        "\"\"\"\n",
        "\n",
        "# 使用已轉換好的版本\n",
        "dataset = load_dataset(\n",
        "    \"FinanceInc/auditor_sentiment\",  # 這是轉換後的版本\n",
        "    #split=\"train\"\n",
        ")\n",
        "\n",
        "print(dataset)\n",
        "\n",
        "print(\"訓練集：\", dataset['train'])\n",
        "print(\"測試集：\", dataset['test'])\n",
        "\n",
        "# 查看資料集的欄位名稱與類型\n",
        "print(\"訓練集欄位：\", dataset[\"train\"].column_names)\n",
        "print(\"測試集欄位：\", dataset[\"test\"].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE5yukdP4CSF",
        "outputId": "6a544e96-ab97-4226-ec6f-0aaf7f041f21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "訓練集前5筆：\n",
            "{'sentence': [\"Altia 's operating profit jumped to EUR 47 million from EUR 6.6 million .\", 'The agreement was signed with Biohit Healthcare Ltd , the UK-based subsidiary of Biohit Oyj , a Finnish public company which develops , manufactures and markets liquid handling products and diagnostic test systems .', 'Kesko pursues a strategy of healthy , focused growth concentrating on sales and services to consumer-customers .', 'Vaisala , headquartered in Helsinki in Finland , develops and manufactures electronic measurement systems for meteorology , environmental sciences , traffic and industry .', 'Also , a six-year historic analysis is provided for these markets .'], 'label': [2, 2, 2, 1, 1]}\n",
            "\n",
            "測試集前5筆：\n",
            "{'sentence': [\"TeliaSonera TLSN said the offer is in line with its strategy to increase its ownership in core business holdings and would strengthen Eesti Telekom 's offering to its customers .\", 'STORA ENSO , NORSKE SKOG , M-REAL , UPM-KYMMENE Credit Suisse First Boston ( CFSB ) raised the fair value for shares in four of the largest Nordic forestry groups .', \"Clothing retail chain Sepp+ñl+ñ 's sales increased by 8 % to EUR 155.2 mn , and operating profit rose to EUR 31.1 mn from EUR 17.1 mn in 2004 .\", 'Lifetree was founded in 2000 , and its revenues have risen on an average by 40 % with margins in late 30s .', \"Nordea Group 's operating profit increased in 2010 by 18 percent year-on-year to 3.64 billion euros and total revenue by 3 percent to 9.33 billion euros .\"], 'label': [2, 2, 2, 2, 2]}\n",
            "\n",
            "資料集的 keys： dict_keys(['train', 'test'])\n"
          ]
        }
      ],
      "source": [
        "# 查看訓練集中前幾筆數據\n",
        "print(\"\\n訓練集前5筆：\")\n",
        "print(dataset[\"train\"][:5])\n",
        "\n",
        "# 查看測試集中前幾筆數據\n",
        "print(\"\\n測試集前5筆：\")\n",
        "print(dataset[\"test\"][:5])\n",
        "\n",
        "# 查看資料集中有哪些 Keys\n",
        "print(\"\\n資料集的 keys：\", dataset.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqRHjN1M4CSF",
        "outputId": "04194e28-3a51-47d6-ba1c-95051cfb12f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "訓練集標籤分佈： Counter({1: 2320, 2: 1077, 0: 480})\n",
            "測試集標籤分佈： Counter({1: 559, 2: 286, 0: 124})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter # 計算列表中每個元素的出現次數\n",
        "\n",
        "\"\"\"\n",
        "為什麼要分析標籤分佈？\n",
        "1. 檢查類別不平衡(Class Imbalance)問題\n",
        "   - 如果某類別樣本過少，模型可能學不好該類別\n",
        "   - 可能需要使用過採樣(oversampling)或欠採樣(undersampling)\n",
        "\n",
        "2. 了解資料特性\n",
        "   - 金融文本中，中性(Neutral)通常佔多數\n",
        "   - 正面和負面情緒相對較少\n",
        "\n",
        "3. 決定評估指標\n",
        "   - 如果類別不平衡嚴重，準確率(Accuracy)可能不適合\n",
        "   - 應該使用 F1-score、Precision、Recall 等指標\n",
        "\"\"\"\n",
        "# label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "# 計算訓練集標籤出現次數\n",
        "label_counts_train = Counter(dataset[\"train\"][\"label\"])\n",
        "print(\"\\n訓練集標籤分佈：\", label_counts_train)\n",
        "\n",
        "# 計算測試集標籤出現次數\n",
        "label_counts_test = Counter(dataset[\"test\"][\"label\"])\n",
        "print(\"測試集標籤分佈：\", label_counts_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRQsEmGS4CSG",
        "outputId": "f82d59c2-2192-4040-eb2d-9f5607cac93e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "訓練集前5筆：\n",
            "                                            sentence  label\n",
            "0  Altia 's operating profit jumped to EUR 47 mil...      2\n",
            "1  The agreement was signed with Biohit Healthcar...      2\n",
            "2  Kesko pursues a strategy of healthy , focused ...      2\n",
            "3  Vaisala , headquartered in Helsinki in Finland...      1\n",
            "4  Also , a six-year historic analysis is provide...      1\n",
            "\n",
            "測試集前5筆：\n",
            "                                            sentence  label\n",
            "0  TeliaSonera TLSN said the offer is in line wit...      2\n",
            "1  STORA ENSO , NORSKE SKOG , M-REAL , UPM-KYMMEN...      2\n",
            "2  Clothing retail chain Sepp+ñl+ñ 's sales incre...      2\n",
            "3  Lifetree was founded in 2000 , and its revenue...      2\n",
            "4  Nordea Group 's operating profit increased in ...      2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd  # 結構化資料處理套件\n",
        "\n",
        "\"\"\"\n",
        "為什麼要轉換成 DataFrame？\n",
        "1. 更直觀的資料檢視：表格形式更容易閱讀和理解\n",
        "2. 豐富的資料處理功能：pandas 提供大量資料清洗工具\n",
        "3. 方便進行統計分析：可以快速計算統計量\n",
        "4. 易於視覺化：可以搭配 matplotlib、seaborn 繪圖\n",
        "\"\"\"\n",
        "\n",
        "# 轉換為 DataFrame\n",
        "df_train = pd.DataFrame(dataset[\"train\"])\n",
        "df_test = pd.DataFrame(dataset[\"test\"])\n",
        "\n",
        "print(\"\\n訓練集前5筆：\")\n",
        "print(df_train.head())\n",
        "\n",
        "print(\"\\n測試集前5筆：\")\n",
        "print(df_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly_2cEa24CSG",
        "outputId": "57087d9f-b5f9-4a7e-cb0c-8a75d3545f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "訓練集空值： sentence    0\n",
            "label       0\n",
            "dtype: int64\n",
            "測試集空值： sentence    0\n",
            "label       0\n",
            "dtype: int64\n",
            "\n",
            "訓練集大小： (3872, 2)\n",
            "測試集大小： (969, 2)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "為什麼要檢查空值和重複值？\n",
        "1. 空值(Null values)問題\n",
        "   - 空值會導致模型訓練失敗或產生錯誤\n",
        "   - 需要決定是刪除還是填補(imputation)\n",
        "\n",
        "2. 重複值(Duplicates)問題\n",
        "   - 重複的句子會讓模型過度擬合該樣本\n",
        "   - 影響模型的泛化能力\n",
        "   - 可能導致評估指標不準確\n",
        "\"\"\"\n",
        "# 檢查空值\n",
        "print(\"\\n訓練集空值：\", df_train.isnull().sum())\n",
        "print(\"測試集空值：\", df_test.isnull().sum())\n",
        "\n",
        "# 刪除重複值（如果有的話）\n",
        "df_train.drop_duplicates(subset=[\"sentence\"], inplace=True)\n",
        "df_test.drop_duplicates(subset=[\"sentence\"], inplace=True)\n",
        "\n",
        "print(\"\\n訓練集大小：\", df_train.shape)\n",
        "print(\"測試集大小：\", df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McOx-gkD4CSG",
        "outputId": "cb31438d-e244-4a6f-cd74-d816ae3f9ccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "資料集劃分：\n",
            "訓練集大小：3101\n",
            "驗證集大小：776 （從訓練集切出，用於訓練過程中的評估）\n",
            "測試集大小：969 （保留到最後才使用，避免資訊洩漏）\n"
          ]
        }
      ],
      "source": [
        "train_val_split = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
        "train_dataset = train_val_split[\"train\"]\n",
        "val_dataset = train_val_split[\"test\"]\n",
        "test_dataset = dataset[\"test\"]\n",
        "print(\"\\n資料集劃分：\")\n",
        "print(f\"訓練集大小：{len(train_dataset)}\")\n",
        "print(f\"驗證集大小：{len(val_dataset)} （從訓練集切出，用於訓練過程中的評估）\")\n",
        "print(f\"測試集大小：{len(test_dataset)} （保留到最後才使用，避免資訊洩漏）\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D648f8Nt4CSG",
        "outputId": "fa277820-47a3-4d14-96f4-c1c8d35c8581",
        "colab": {
          "referenced_widgets": [
            "27e2b2c5be34433db23546535bed8258",
            "b8d75cb2b7a84394bf8db25ae785a53c",
            "3e4eca448f9e44d9bfc9aab2b56ec8aa",
            "a62e724d1716440cbb563d7e145090a4",
            "bc969d3e672e4c25b22dd014df08018b",
            "93f07052fe764c3a83e68552fd693980",
            "f4dbd8543d63457bb0f815247f227274"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "使用的模型：ProsusAI/finbert\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27e2b2c5be34433db23546535bed8258",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8d75cb2b7a84394bf8db25ae785a53c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e4eca448f9e44d9bfc9aab2b56ec8aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a62e724d1716440cbb563d7e145090a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc969d3e672e4c25b22dd014df08018b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3101 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93f07052fe764c3a83e68552fd693980",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/776 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4dbd8543d63457bb0f815247f227274",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/969 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer  # AutoTokenizer 可以根據指定的模型名稱，自動選擇和載入與該模型相匹配的分詞器\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "=============================================================================\n",
        "【作業 1：模型選擇】\n",
        "=============================================================================\n",
        "\n",
        "什麼是 Tokenizer？\n",
        "- 將文本轉換成模型可以理解的數字序列\n",
        "- 不同模型有不同的 tokenization 策略\n",
        "- BERT 使用 WordPiece，將詞切成子詞單元\n",
        "\n",
        "可選模型比較：\n",
        "\n",
        "1. bert-base-uncased (預設)\n",
        "   優點：經典模型，效果穩定，社群資源豐富\n",
        "   缺點：模型較大(110M參數)，訓練速度較慢\n",
        "   適用：標準 NLP 任務，對效果要求高\n",
        "\n",
        "2. distilbert-base-uncased\n",
        "   優點：BERT 的蒸餾版本，速度快 60%，模型小 40%\n",
        "   缺點：準確率略低於 BERT (約 2-3%)\n",
        "   適用：計算資源有限，需要快速迭代\n",
        "\n",
        "3. roberta-base\n",
        "   優點：改進的 BERT，通常效果更好\n",
        "   缺點：訓練時間稍長\n",
        "   適用：追求更高準確率\n",
        "\n",
        "4. albert-base-v2\n",
        "   優點：參數共享技術，模型很小但效果不錯\n",
        "   缺點：推理速度較慢\n",
        "   適用：記憶體受限的場景\n",
        "\n",
        "5. ProsusAI/finbert\n",
        "   優點：專門在金融文本上預訓練，理解金融術語\n",
        "   缺點：資料集較小，可能過擬合\n",
        "   適用：金融領域專業任務（最推薦！）\n",
        "\n",
        "6. bert-base-chinese\n",
        "   優點：支援中文\n",
        "   缺點：英文效果不佳\n",
        "   適用：中文金融文本分析\n",
        "\n",
        "評估面向：\n",
        "✓ 訓練時間\n",
        "✓ 驗證集 F1-score\n",
        "✓ 測試集 F1-score\n",
        "✓ 模型大小\n",
        "✓ 推理速度\n",
        "\"\"\"\n",
        "# 使用BERT Tokenizer 進行Tokenization(分詞)\n",
        "model_name = \"ProsusAI/finbert\"  # 請修改這裡！\n",
        "\n",
        "print(f\"\\n使用的模型：{model_name}\")\n",
        "# ============================================================================\n",
        "\n",
        "\"\"\"\n",
        "為什麼要使用 AutoTokenizer？\n",
        "- 自動根據模型名稱載入對應的 tokenizer\n",
        "- 確保 tokenization 策略與模型匹配\n",
        "- 避免手動管理不同模型的 tokenizer\n",
        "\"\"\"\n",
        "from transformers import AutoTokenizer  # AutoTokenizer 可以根據指定的模型名稱，自動選擇和載入與該模型相匹配的分詞器\n",
        "\n",
        "# 使用指定的 Tokenizer 進行 Tokenization(分詞)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Tokenization 的關鍵參數：\n",
        "\n",
        "1. padding=\"max_length\"\n",
        "   - 將所有句子補齊到相同長度\n",
        "   - 原因：深度學習模型要求批次(batch)內的輸入長度一致\n",
        "   - 較短的句子會用 [PAD] token 填充\n",
        "\n",
        "2. truncation=True\n",
        "   - 截斷超過最大長度的句子\n",
        "   - BERT 的最大長度通常是 512 tokens\n",
        "   - 避免超長句子導致記憶體不足\n",
        "\n",
        "3. return_tensors=\"pt\" (後面會用到)\n",
        "   - 返回 PyTorch tensor 格式\n",
        "   - 可以直接輸入模型進行運算\n",
        "\"\"\"\n",
        "\n",
        "# 定義 Tokenize 函數，用於將句子轉換為 Token\n",
        "def tokenize_function(example):\n",
        "    # 使用 tokenizer 將每個句子進行分詞\n",
        "    # 設定 padding=\"max_length\" 確保所有句子補齊至固定長度\n",
        "    # 設定 truncation=True 以截斷超過最大長度的句子\n",
        "    return tokenizer(example[\"sentence\"], padding=\"max_length\", truncation=True)\n",
        "\"\"\"\n",
        "Tokenization 結果說明：\n",
        "\n",
        "input_ids：\n",
        "- 將文字轉換成數字 ID\n",
        "- 例如：[101, 2043, 2003, 1996, ...]\n",
        "- 101 是 [CLS] token，表示句子開始\n",
        "- 102 是 [SEP] token，表示句子結束\n",
        "\n",
        "attention_mask：\n",
        "- 標記哪些位置是真實 token (1)，哪些是 padding (0)\n",
        "- 讓模型知道應該關注哪些部分\n",
        "\n",
        "token_type_ids：\n",
        "- 區分不同句子（在句子對任務中使用）\n",
        "- 在單句分類中全部為 0\n",
        "\"\"\"\n",
        "# 對訓練集、驗證集和測試集進行 Tokenize\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VnhHOJT4CSH",
        "outputId": "d4f6a82a-5ee6-419b-ab03-78a612f4671b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tokenized 訓練集第一筆：\n",
            "{'sentence': [\"The financial impact is estimated to be some 1.5 MEUR annual improvement in the division 's result , starting from fiscal year 2007 .\"], 'label': [2], 'input_ids': [[101, 1996, 3361, 4254, 2003, 4358, 2000, 2022, 2070, 1015, 1012, 1019, 2033, 3126, 3296, 7620, 1999, 1996, 2407, 1005, 1055, 2765, 1010, 3225, 2013, 10807, 2095, 2289, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "\n",
            "Tokenized 驗證集第一筆：\n",
            "{'sentence': [\"We have also cut our price projections for paper and packaging , '' an analyst with Goldman Sachs said on a note on Monday .\"], 'label': [0], 'input_ids': [[101, 2057, 2031, 2036, 3013, 2256, 3976, 21796, 2005, 3259, 1998, 14793, 1010, 1005, 1005, 2019, 12941, 2007, 17765, 22818, 2056, 2006, 1037, 3602, 2006, 6928, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "\n",
            "Tokenized 測試集第一筆：\n",
            "{'sentence': [\"TeliaSonera TLSN said the offer is in line with its strategy to increase its ownership in core business holdings and would strengthen Eesti Telekom 's offering to its customers .\"], 'label': [2], 'input_ids': [[101, 10093, 7951, 5643, 2527, 1056, 4877, 2078, 2056, 1996, 3749, 2003, 1999, 2240, 2007, 2049, 5656, 2000, 3623, 2049, 6095, 1999, 4563, 2449, 9583, 1998, 2052, 12919, 25212, 16643, 10093, 5937, 5358, 1005, 1055, 5378, 2000, 2049, 6304, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n",
            "\n",
            "訓練集特徵： {'sentence': Value('string'), 'label': Value('int64'), 'input_ids': List(Value('int32')), 'token_type_ids': List(Value('int8')), 'attention_mask': List(Value('int8'))}\n",
            "驗證集特徵： {'sentence': Value('string'), 'label': Value('int64'), 'input_ids': List(Value('int32')), 'token_type_ids': List(Value('int8')), 'attention_mask': List(Value('int8'))}\n",
            "測試集特徵： {'sentence': Value('string'), 'label': Value('int64'), 'input_ids': List(Value('int32')), 'token_type_ids': List(Value('int8')), 'attention_mask': List(Value('int8'))}\n"
          ]
        }
      ],
      "source": [
        "# 查看 Tokenized 資料\n",
        "print(\"\\nTokenized 訓練集第一筆：\")\n",
        "print(tokenized_train[:1])\n",
        "\n",
        "print(\"\\nTokenized 驗證集第一筆：\")\n",
        "print(tokenized_val[:1])\n",
        "\n",
        "print(\"\\nTokenized 測試集第一筆：\")\n",
        "print(tokenized_test[:1])\n",
        "# 確認 tokenized_datasets 是否包含需要的欄位\n",
        "print(\"\\n訓練集特徵：\", tokenized_train.features)\n",
        "print(\"驗證集特徵：\", tokenized_val.features)\n",
        "print(\"測試集特徵：\", tokenized_test.features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B6hjgeKNCOY"
      },
      "source": [
        "### <b>建立模型</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96OgYlz04CSH",
        "outputId": "5629cd74-e62e-45a9-ebde-825dbfc52bd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch  # 深度學習框架\n",
        "\"\"\"\n",
        "為什麼要檢查 GPU？\n",
        "- GPU 的平行運算能力遠超 CPU（通常快 10-100 倍）\n",
        "- 深度學習涉及大量矩陣運算，適合 GPU 加速\n",
        "- 如果有 GPU 可用，應該優先使用\n",
        "\n",
        "CUDA 是什麼？\n",
        "- NVIDIA 的平行運算平台\n",
        "- PyTorch 透過 CUDA 調用 GPU\n",
        "- torch.cuda.is_available() 檢查是否有可用的 GPU\n",
        "\"\"\"\n",
        "# 如果有GPU就用GPU，沒有GPU用CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0flzM1yf4CSH",
        "outputId": "2f655c8e-f349-45e9-9ff7-9035d8303d65",
        "colab": {
          "referenced_widgets": [
            "af34cbf229504a3590d4524640ac8a52",
            "31030aba5408442fb2f6e68b668053ad"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af34cbf229504a3590d4524640ac8a52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31030aba5408442fb2f6e68b668053ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification  # 序列分類模型\n",
        "\"\"\"\n",
        "什麼是遷移學習(Transfer Learning)？\n",
        "\n",
        "1. 預訓練(Pre-training)階段\n",
        "   - 在大規模文本語料上預訓練\n",
        "   - 學習通用的語言理解能力\n",
        "   - BERT 在 BookCorpus 和 Wikipedia 上訓練\n",
        "\n",
        "2. 微調(Fine-tuning)階段\n",
        "   - 在特定任務上微調模型\n",
        "   - 只需要較少的標註資料\n",
        "   - 適應特定領域（如金融文本）\n",
        "\n",
        "為什麼設定 num_labels=3？\n",
        "- 我們的任務是三分類：Negative, Neutral, Positive\n",
        "- 模型最後會輸出 3 個分數(logits)\n",
        "- 透過 softmax 轉換成機率分佈\n",
        "\n",
        "model.to(device) 的作用？\n",
        "- 將模型參數移動到 GPU 上\n",
        "- 確保模型和輸入資料在同一個裝置\n",
        "\"\"\"\n",
        "\n",
        "# 載入模型（使用作業區域 1 選擇的模型）\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "model.to(device)  # 將模型移到對應裝置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmsrHYYw4CSH"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments  # 包裝訓練參數\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",          # 訓練結果的儲存位置，包括模型檔案和預測結果。\n",
        "    eval_strategy=\"epoch\",     # 設置評估策略為每個訓練輪次（epoch）結束後進行一次評估。\n",
        "    learning_rate=2e-5,              # 設置學習率，這裡使用 2e-5，通常較小的學習率更適合微調預訓練模型。\n",
        "    per_device_train_batch_size=4,   # 設定每個裝置（如每張 GPU）的訓練批次大小為 4。\n",
        "    per_device_eval_batch_size=4,    # 設定每個裝置的評估批次大小為 4。\n",
        "    num_train_epochs=3,              # 訓練輪次設定為 3，模型將完整遍歷訓練集三次。\n",
        "    weight_decay=0.01,               # 設置權重衰減（L2正則化）參數，這裡為 0.01，用於防止過擬合。\n",
        "    logging_dir=\"./logs\",            # 日誌存放目錄，用於儲存 TensorBoard 或其他日誌。\n",
        "    logging_steps=10,                # 設置每 10 個步驟記錄一次訓練信息，便於監控訓練過程。\n",
        "    report_to=\"none\",                 # 不將訓練日誌發送到任何平臺（如 TensorBoard），可以改為 \"tensorboard\" 以啟用。\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-54H26m4CSH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "\n",
        "\"\"\"\n",
        "為什麼需要這些評估指標？\n",
        "\n",
        "1. Accuracy (準確率)\n",
        "   公式：(預測正確的樣本數) / (總樣本數)\n",
        "   優點：直觀易懂\n",
        "   缺點：在類別不平衡時會誤導\n",
        "\n",
        "2. Precision (精確率)\n",
        "   公式：(真正例) / (真正例 + 假正例)\n",
        "   意義：預測為正例的樣本中，真正為正例的比例\n",
        "   應用：當誤報代價高時重視精確率\n",
        "\n",
        "3. Recall (召回率)\n",
        "   公式：(真正例) / (真正例 + 假負例)\n",
        "   意義：所有正例中，被正確預測的比例\n",
        "   應用：當漏報代價高時重視召回率\n",
        "\n",
        "4. F1-score (F1分數)\n",
        "   公式：2 * (Precision * Recall) / (Precision + Recall)\n",
        "   意義：精確率和召回率的調和平均\n",
        "   優點：綜合考慮兩者，適合類別不平衡\n",
        "\n",
        "為什麼使用 average=\"weighted\"？\n",
        "- 根據每個類別的樣本數加權平均\n",
        "- 考慮類別不平衡的影響\n",
        "- 更能反映整體表現\n",
        "\n",
        "在金融情緒分析中的重要性：\n",
        "- Precision 高：減少誤判（例如誤把中性當成正面）\n",
        "- Recall 高：不錯過重要信號（例如不漏掉負面新聞）\n",
        "- F1-score 高：整體表現好\n",
        "\"\"\"\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids  # 取得真實值的id\n",
        "    preds = np.argmax(pred.predictions, axis=1)  # 預測值找到最高機率的索引\n",
        "    accuracy = accuracy_score(labels, preds)  # 計算準確率\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")  # 計算其他指標\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TerrWSb4CSH",
        "outputId": "31b9adf7-2a4b-4ff4-cb73-d625bf738c7e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2328' max='2328' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2328/2328 21:32, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.236900</td>\n",
              "      <td>0.490565</td>\n",
              "      <td>0.872423</td>\n",
              "      <td>0.874108</td>\n",
              "      <td>0.872423</td>\n",
              "      <td>0.869854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.278600</td>\n",
              "      <td>0.608179</td>\n",
              "      <td>0.868557</td>\n",
              "      <td>0.875764</td>\n",
              "      <td>0.868557</td>\n",
              "      <td>0.870047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>0.620478</td>\n",
              "      <td>0.876289</td>\n",
              "      <td>0.877076</td>\n",
              "      <td>0.876289</td>\n",
              "      <td>0.876593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2328, training_loss=0.3154320978536351, metrics={'train_runtime': 1294.2161, 'train_samples_per_second': 7.188, 'train_steps_per_second': 1.799, 'total_flos': 2447744125123584.0, 'train_loss': 0.3154320978536351, 'epoch': 3.0})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "\"\"\"\n",
        "Trainer 類別的作用：\n",
        "- 封裝了完整的訓練流程\n",
        "- 自動處理：\n",
        "  ✓ 梯度計算和參數更新\n",
        "  ✓ 批次資料載入\n",
        "  ✓ 學習率調整\n",
        "  ✓ 驗證集評估\n",
        "  ✓ Checkpoint 儲存\n",
        "  ✓ 日誌記錄\n",
        "\n",
        "為什麼使用高階 API？\n",
        "- 減少樣板代碼(boilerplate code)\n",
        "- 避免常見錯誤\n",
        "- 專注於模型和資料\n",
        "- 便於快速實驗\n",
        "\n",
        "訓練過程中會發生什麼？\n",
        "1. 前向傳播(Forward pass)\n",
        "   - 輸入資料經過模型，得到預測結果\n",
        "\n",
        "2. 計算損失(Loss calculation)\n",
        "   - 比較預測結果和真實標籤\n",
        "   - 使用交叉熵損失(Cross-entropy loss)\n",
        "\n",
        "3. 反向傳播(Backward pass)\n",
        "   - 計算損失對參數的梯度\n",
        "\n",
        "4. 參數更新(Parameter update)\n",
        "   - 使用梯度和學習率更新參數\n",
        "   - 優化器：AdamW (Adam with weight decay)\n",
        "\n",
        "5. 驗證評估(Validation)\n",
        "   - 每個 epoch 結束後在驗證集上評估\n",
        "   - 不更新參數，只計算指標\n",
        "\"\"\"\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,  # 使用訓練集\n",
        "    eval_dataset=tokenized_val,     # 使用驗證集（從訓練集切出來的）\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# 開始訓練\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2CSuye8NPbm"
      },
      "source": [
        "### <b>結果評估</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkqnGYL14CSH",
        "outputId": "4db7d590-3868-4f88-dae5-39cc57608c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 驗證集評估結果 ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='194' max='194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [194/194 00:26]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6204783320426941, 'eval_accuracy': 0.8762886597938144, 'eval_precision': 0.877075862841775, 'eval_recall': 0.8762886597938144, 'eval_f1': 0.876592504682786, 'eval_runtime': 26.1839, 'eval_samples_per_second': 29.636, 'eval_steps_per_second': 7.409, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# 評估模型在驗證集的表現\n",
        "\n",
        "print(\"\\n=== 驗證集評估結果 ===\")\n",
        "val_result = trainer.evaluate(eval_dataset=tokenized_val)\n",
        "print(val_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l6t2yFd4CSH",
        "outputId": "fb4ff0f6-185c-422a-c659-c99a5b306f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 測試集評估結果（最終評估）===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='437' max='194' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [194/194 01:17]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6447749137878418, 'eval_accuracy': 0.8720330237358102, 'eval_precision': 0.8732292913913698, 'eval_recall': 0.8720330237358102, 'eval_f1': 0.872451745069848, 'eval_runtime': 32.6564, 'eval_samples_per_second': 29.673, 'eval_steps_per_second': 7.441, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "# 評估模型在測試集的表現（最終評估）\n",
        "print(\"\\n=== 測試集評估結果（最終評估）===\")\n",
        "test_result = trainer.evaluate(eval_dataset=tokenized_test)\n",
        "print(test_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSgCkDKhwF_o"
      },
      "source": [
        "### <b2>使用測試集進行預測展示</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrponlzH4CSH",
        "outputId": "42081c2a-6ac0-480b-a035-3395231ce1c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 測試集句子展示 ===\n",
            "以下是測試集中的其中 100 個句子：\n",
            "\n",
            "[101] In 2008 , it generated net sales of EUR 9.3 million USD 13.1 m .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[102] In August , Latvijas Finieris ordered all production lines for a new green veneer mill to be built in Ukmerge , Lithuania .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[103] Jacobs has been supporting Storengy 's investment of developing storage sites since 2006 as owner 's engineer .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[104] One of the challenges in the oil production in the North Sea is scale formation that can plug pipelines and halt production .\n",
            "    真實標籤：Negative\n",
            "\n",
            "[105] Rental of building equipment accounted for 88 percent of the operating income .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[106] Sanoma will continue to focus on investing in digital media and on strengthening its market positions .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[107] The acquisition is part of Suomen Helasto 's strategy to expand the LukkoExpert Security chain , Suomen Helasto CEO Kimmo Uusimaki said .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[108] The corresponding share capital increase , EUR 1,012,945.50 was entered in the Trade Register today .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[109] The expansion includes the doubling of the floor space and the addition of more lifting capacity and production equipment .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[110] The phones are targeted at first time users in growth markets .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[111] The repayment of EUR 105 million debenture bonds is related to the Company 's previous announcement on October 21 , 2009 to collect irrevocable selling commitments from the holders of its subordinated debenture bonds .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[112] The total area of the Gorelovo plant is about 22,000 sq m. Atria invested about EURO 70mn in the plant , which should double Atria Russia 's production capacity in the St Petersburg area .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[113] U.S. District Judge Douglas P. Woodlock yesterday extended a Jan. 17 temporary restraining order until March 7 .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[114] UK 's Sarantel to outsource part of its processes to Elcoteq plant in Estonia LONDON , Oct 13 , BNS - The British miniature antennas maker Sarantel has signed an agreement to outsource its assembly test and supply chain processes to the plant of Elcoteq in the Estonian capital Tallinn .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[115] Earnings per share ( EPS ) for the first quarter 2007 amounted to EUR0 .07 , up from EUR0 .04 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[116] Ruukki Romania , the local arm of Finnish metal producer Ruukki , increased its capital by 900,000 euro ( $ 1.14 mln ) through cash contribution , it was reported on September 19 , 2006 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[117] The growth of net sales has continued favourably in the Middle East and Africaand in Asia Pacific .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[118] Following the increase , Huhtamaki Oyj 's registered share capital is EUR 358,706,290.00 and the number of shares outstanding is 105,501,850 .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[119] Following this increase Huhtamaki 's registered share capital is EUR360 .62 m and the number of shares outstanding is 106,063,320 .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[120] Under the agreement , Pfizer has been funding Biotie 's research activities on the PDE10 phosphodiesterase 10 inhibitor program since its start in late 2006 and has the sole authority to develop discovered compounds .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[121] `` Our extensive co-operation will also bolster SysOpen Digia 's position in the domestic operator market , '' Kallioranta adds .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[122] Mr Priit Kasak , Balti Metsamasina 's owner , said the Rakvere-based company wishes to increase Valmet 's market share from 27 % to a third in a couple of years .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[123] Finnish Cargotec 's Kalmar , the business area providing container handling solutions , has been awarded an order for a further ten E-One rubber-tyred gantry RTG cranes from Saigon Newport Company SNP , in Vietnam .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[124] Bilfinger investors cheered the agreement , pushing shares up 7 % , or & euro ; 3.30 , to & euro ; 50.29 , in afternoon trade .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[125] CDP was established on the initiative of institutional investors ; however , the annually published results also interest an increasing number of customers and other interest groups of the reporting companies .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[126] The original contract was signed last summer .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[127] ` It is a testament to the quality of our LTE solution and our commitment to the Japanese market ' , he added .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[128] 18 January 2010 - Finnish IT consultancy Trainers ' House Oyj HEL : TRH1V said last Friday it resolved to issue a EUR5m hybrid bond to domestic investors in a bid to strengthen its capital structure .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[129] ALEXANDRIA , Va. , Oct. 15 -- Aaron Moss of Hampshire , Great Britain , has developed an ornamental design for a handset , the U.S. Patent & Trademark Office announced .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[130] In the second quarter of 2010 , the group 's pretax loss narrowed to EUR 400,000 from EUR 600,000 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[131] Finnish sports equipment maker Amer Sports Oyj ( HEL : AMEAS ) said today that its net loss narrowed to EUR 16.9 million ( USD 22.3 m ) in the second quarter of 2010 from EUR 23.2 million in the corresponding period a year earlier .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[132] 20 October 2010 - Finnish metal products company Componenta Oyj HEL : CTH1V said yesterday that its net loss narrowed to EUR7m for the first nine months of 2010 from EUR23 .3 m for the same period of 2009 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[133] In contrast , the company 's net loss for the third quarter of 2009 contracted to EUR 76 million from EUR 256 million for the corresponding period a year ago .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[134] In the second quarter of 2010 , Raute 's net loss narrowed to EUR 123,000 from EUR 1.5 million in the same period of 2009 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[135] Metsaliitto , however , narrowed its net loss for the second quarter of 2007 to 5.0 mln euro $ 6.9 mln from 61 mln euro $ 83.7 mln a year ago .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[136] Airvana 's UMTS Home Base Station femto cell uses software-based functionality and off-the-shelf silicon to accelerate feature development and reduce product cost .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[137] Profit before taxes amounted to EUR 56.5 mn , down from EUR 232.9 mn a year ago .\n",
            "    真實標籤：Negative\n",
            "\n",
            "[138] The plan is estimated to generate some EUR 5 million ( USD 6.5 m ) in cost savings on an annual basis .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[139] Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[140] Also construction expenses have gone up in Russia .\n",
            "    真實標籤：Negative\n",
            "\n",
            "[141] `` UPM 's deliveries increased during the third quarter by 4 percent , and the efficiency of operations improved , '' Chief Executive Jussi Pesonen said .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[142] Stora Enso R shares rose 1.20 pct to 11.84 eur , UPM-Kymmene was also dragged higher , rising 1.68 pct to 17.56 eur and M-Real B added 2.38 pct to 4.30 eur .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[143] Earnings per share ( EPS ) amounted to EUR0 .98 , up from the loss of EUR0 .02 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[144] Operating result including non-recurring items rose to EUR 146mn from a loss of EUR 267mn in 2009 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[145] Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[146] Earnings per share EPS amounted to EUR0 .03 , up from the loss of EUR0 .08 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[147] The investments and operational changes enable additional optimisation of the working hours and thereby further cost savings of some 7 % -9 % .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[148] By 14:29 CET on Monday , shares in Bavarian Nordic had climbed 1.21 % to DKK250 on the stock exchange in Copenhagen after having lost 7.41 % in the past month .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[149] For example , net sales increased by 5.9 % from the first quarter , and EBITDA increased from a negative EUR 0.2 mn in the first quarter of 2009 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[150] Cencorp estimates that its net sales in the last quarter will be as earlier stated , EUR4 .3 m to EUR5 .0 m , and operating profit (EBIT)is estimated to be positive .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[151] `` After the share purchase is completed , financing will also be provided to expand Latvia 's broadband infrastructure and to develop new areas of business , including acquisitions of other companies . ''\n",
            "    真實標籤：Positive\n",
            "\n",
            "[152] `` The margarine business has been put into good shape in the last two years , making it a natural addition to Bunge , which is looking to leverage its position in the Central and Northern European markets , '' Raisio CEO Matti Rihko said in a statement .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[153] `` This is a win for all OEMs targeting to develop WiMAX products .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[154] At the same time , sales development in Russia was boosted by the opening of Stockmann Nevsky Centre in St Petersburg .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[155] Benefon , a wireless and GPS technology company , will supply Karputer with its TWIG navigation platform , a GPS satellite navigation and voice guidance service .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[156] Combining this deep domain expertise with our Application Service Management ASM and outsourcing service offerings has now proved to be a winning combination .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[157] Exports accounted for 65.4 % of net sales , representing an all time record for the company .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[158] Finnish construction company YIT Oyj said on November 13 , 2007 it won a 70 mln euro $ 102.8 mln contract to construct the new office building for local property company Tapiola Real Estate Oy .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[159] Of the price , Kesko 's share is 10 mln euro $ 15.5 mln and it will recognize a gain of 4.0 mln euro $ 6.2 mln on the disposal which will be included in the result for the second quarter of 2008 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[160] Performance in the second half of 2009 exceeded expectations .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[161] Talvivaara also maintains its assumption of turning cash flow positive before the year end .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[162] Thanksto improvements in demand and the adjustments we have made , theutilization rates of Cramo 's fleet have substantiallyimproved . ''\n",
            "    真實標籤：Positive\n",
            "\n",
            "[163] The estimated synergy benefits are at least EUR7m annually .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[164] The Group 's business is balanced by its broad portfolio of sports and presence in all major markets .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[165] When the situation normalises , the company will be able to increase the amount of residential units for sale in St Petersburg and Moscow , in particular .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[166] `` Stonesoft sees great promise in the future of IPv6 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[167] `` The trend in the sports and leisure markets was favorable in the first months of the year .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[168] `` We continued actively to focus R&D and to position our offering away from point solutions towards dynamic end-to-end solutions , '' Ervio stated .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[169] According to Finnish pension insurance company Varma , Varma was the recipient of over two thirds of the revenue of the earnings-related pension cover that was under competitive tendering in Finland .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[170] Finnish construction group Lemmink+ñinen has been awarded two road building contracts by the Lithuanian transport administration .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[171] And the broker repeated its ` buy ' rating , based on expectations that current restructuring will lead to a clear improvement in performance in Europe in 2007 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[172] Cision says the sale will return its U.K. operation to profitability .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[173] Comptel , a vendor of dynamic Operations Support System ( OSS ) software , has been selected by Orascom Telecom ( OTH ) as partner for provisioning and activation solutions for mobile services .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[174] DMASIA-16 August 2006-Benefon extends manufacturing capability with ASMobile -® 2006 Digitalmediaasia.com & DMA Ltd. .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[175] Fiskars has a strong portfolio of international brands , which include Fiskars , Iittala , Gerber , Silva and Buster .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[176] Furthermore , efficiency improvement measures initiated earlier are now bearing fruit , '' CEO Jan Lang said .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[177] Helsingin Uutiset , Vantaan Sanomat and Lansivayla reach some 385,000 readers , or more than 40 % of the consumers in the greater Helsinki region .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[178] It also has potential clients in the growing environmental and recycling technology sectors .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[179] ( ADP News ) - Oct 31 , 2008 - Finnish food company Raisio Oyj ( OMX : RAIVV ) said today that its net profit jumped to EUR 16.4 million ( USD 20.9 m ) for the first nine months of 2008 from EUR 1.1 million for the same period of 2\n",
            "    真實標籤：Positive\n",
            "\n",
            "[180] Net sales in 2007 totalled EUR 329 million and the operating margin was above 19 % .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[181] NORDIC BUSINESS REPORT-26 June 2006-Metso Corporation wins EUR50m equipment order in Australia -® 1998-2006 M2 COMMUNICATIONS LTD The Finnish engineering and technology group Metso Corporation said on Monday ( 26 June ) that it has received a EUR50m equipment order in Australia .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[182] Outotec 's net profit for the second quarter of 2007 jumped to 16.8 mln euro ( $ 23.1 mln ) from 4.6 mln euro ( $ 6.3 mln ) a year ago .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[183] Panostaja Oyj s ( Panostaja ) Board of Directors decided on 16 December 2010 on a new long-term incentive and commitment plan for members of the management team .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[184] Raute Corporation has received orders worth over EUR 12 million from OOO Ilim Bratsk DOK in Russia .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[185] Recovery has been evident in the liquid handling business , particularly in areas outside Europe and primarily in North America and Asia .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[186] Speaking to just-drinks today , a spokesperson for Olvi said : `` We have performed very well in all four countries we operate in - namely , Finland , Estonia , Latvia and Lithuania . ''\n",
            "    真實標籤：Positive\n",
            "\n",
            "[187] Sports equipment sales also progressed well owing to the prolonged winter season .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[188] The acquisition of Kaupthing Sverige will bring a significant positive non-recurring addition to the group 's performance .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[189] The companies have agreed on long-term cooperation to mechanise harvesting in Stora Enso 's eucalyptus plantations in Southern China .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[190] The company aims to maintain this trend in profitability during the current year .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[191] The mill has long traditions and holds an established position in the markets .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[192] This is Done Logistics ' largest order in Norway , the diversified group said .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[193] This resulted in improved sales figures in Sweden .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[194] Vaisala also said it expects net sales of EUR 253.2 million for 2010 , compared with EUR 252.2 million recorded in 2009 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[195] 21 December 2010 - Finnish industrial machinery company Wartsila Oyj Abp HEL : WRT1V said yesterday it had won an order to design a liquefied natural gas LNG powered platform supply vessel PSV for Norwegian oil service provider Eidesvik Offshore ASA OSL : EIOF .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[196] Finnish Outotec has been awarded a contract to supply a new zinc roaster with gas cleaning and sulphuric acid plant for the OZK Kardzhali zinc smelter in Bulgaria .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[197] CEO Erkki J+ñrvinen is happy with the company 's performance in 2010 .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[198] Finnish construction group Lemminkainen Oyj HEL : LEM1S said today it has won a contract to provide technical services for the Nevsky Centre shopping mall to be opened in November in St Petersburg , Russia .\n",
            "    真實標籤：Positive\n",
            "\n",
            "[199] Honka 's subsidiaries in France and Germany will also benefit by , for example , arranging customer events in conjunction with World Cup skiing competitions .\n",
            "    真實標籤：Neutral\n",
            "\n",
            "[200] Operating profit improved by 39.9 % to EUR 18.0 mn from EUR12 .8 mn .\n",
            "    真實標籤：Positive\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 先展示測試集中的句子，讓學生了解有哪些資料\n",
        "print(\"\\n=== 測試集句子展示 ===\")\n",
        "print(\"以下是測試集中的其中 100 個句子：\\n\")\n",
        "\n",
        "label_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "\n",
        "for i in range(101,201):\n",
        "    sentence = test_dataset[i][\"sentence\"]\n",
        "    label = test_dataset[i][\"label\"]\n",
        "    print(f\"[{i}] {sentence}\")\n",
        "    print(f\"    真實標籤：{label_map[label]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z01NW-Er4CSH",
        "outputId": "238d3241-fcf0-4ac5-e555-2dc46a1a9cae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "你選擇測試的句子索引：[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
            "\n",
            "=== 開始預測 ===\n",
            "\n",
            "你選擇的 100 個句子的預測結果：\n",
            "\n",
            "9. 測試集索引 [9]\n",
            "   句子：Nyrstar has also agreed to supply to Talvivaara up to 150,000 tonnes of sulphuric acid per annum for use in Talvivaara 's leaching process during the period of supply of the zinc in concentrate .\n",
            "   真實標籤：Positive\n",
            "   預測標籤：Neutral\n",
            "   結果：✗ 錯誤\n",
            "\n",
            "22. 測試集索引 [22]\n",
            "   句子：The circuit 's overall production rate on a weekly basis is now in excess of an average of 40,000 tonnes per day , with volumes in excess of 50,000 tonnes per day being reached on individual days .\n",
            "   真實標籤：Positive\n",
            "   預測標籤：Neutral\n",
            "   結果：✗ 錯誤\n",
            "\n",
            "64. 測試集索引 [64]\n",
            "   句子：Finnish Componenta has published its new long-term strategy for the period 2011-2015 with the aim of growing together with its customers .\n",
            "   真實標籤：Neutral\n",
            "   預測標籤：Positive\n",
            "   結果：✗ 錯誤\n",
            "\n",
            "78. 測試集索引 [78]\n",
            "   句子：Xerox and Stora Enso have teamed up to tailor the iGen3 to the short-run , on-demand packaging market .\n",
            "   真實標籤：Positive\n",
            "   預測標籤：Neutral\n",
            "   結果：✗ 錯誤\n",
            "\n",
            "79. 測試集索引 [79]\n",
            "   句子：As previously announced , GeoSentric Oyj entered into financing agreements with its lead investor on June 30 , 2010 enabling the Company to receive financing up to the aggregate amount of 6M .\n",
            "   真實標籤：Neutral\n",
            "   預測標籤：Positive\n",
            "   結果：✗ 錯誤\n",
            "\n",
            "83. 測試集索引 [83]\n",
            "   句子：Compared with the FTSE 100 index , which rose 51.5 points ( or 0.9 % ) on the day , this was a relative price change of -0.6 % .\n",
            "   真實標籤：Neutral\n",
            "   預測標籤：Positive\n",
            "   結果：✗ 錯誤\n",
            "\n",
            "95. 測試集索引 [95]\n",
            "   句子：`` Residentialconstruction in particular has picked up in several markets .\n",
            "   真實標籤：Positive\n",
            "   預測標籤：Neutral\n",
            "   結果：✗ 錯誤\n",
            "\n",
            "96. 測試集索引 [96]\n",
            "   句子：After the transaction , Alma Media raised its stake in Talentum to 30.65 % of the shares and some 31.12 % of voting rights .\n",
            "   真實標籤：Positive\n",
            "   預測標籤：Neutral\n",
            "   結果：✗ 錯誤\n",
            "\n",
            "99. 測試集索引 [99]\n",
            "   句子：Calls to the switchboard and directory services have decreased significantly since our employees now have up-to-date contact information from all their colleagues and customers on their phone and can place the call directly .\n",
            "   真實標籤：Neutral\n",
            "   預測標籤：Negative\n",
            "   結果：✗ 錯誤\n",
            "\n",
            "準確率：91/100 = 91.00%\n"
          ]
        }
      ],
      "source": [
        "# 請從上面顯示的測試集句子中，選擇你想要測試的句子索引\n",
        "#\n",
        "# 選擇特定的句子索引\n",
        "# 例如：test_indices = [0, 5, 10, 15, 19]\n",
        "#\n",
        "# 提示：\n",
        "# - 可以選擇不同情緒的句子來測試\n",
        "# - 觀察模型在哪些句子上預測正確，哪些預測錯誤\n",
        "# - 思考為什麼模型會預測錯誤\n",
        "\n",
        "# test_indices = [3, 13, 26, 44, 49]  # 請修改這裡！選擇你想測試的句子索引\n",
        "\n",
        "test_indices = list(range(1, 101))\n",
        "\n",
        "print(f\"\\n你選擇測試的句子索引：{test_indices}\")\n",
        "# ============================================================================\n",
        "\n",
        "# 根據選擇的索引，取得測試句子\n",
        "test_texts = [test_dataset[i][\"sentence\"] for i in test_indices]\n",
        "true_labels = [test_dataset[i][\"label\"] for i in test_indices]\n",
        "\n",
        "print(\"\\n=== 開始預測 ===\\n\")\n",
        "\n",
        "\"\"\"\n",
        "預測流程說明：\n",
        "\n",
        "1. 取得測試句子和真實標籤\n",
        "   - 根據選擇的索引提取句子\n",
        "\n",
        "2. Tokenization\n",
        "   - 將句子轉換成模型輸入格式\n",
        "   - return_tensors=\"pt\" 返回 PyTorch tensor\n",
        "\n",
        "3. 模型推理\n",
        "   - 將 tokenized 資料輸入模型\n",
        "   - 得到 logits（未標準化的分數）\n",
        "\n",
        "4. 預測類別\n",
        "   - 使用 argmax 取得分數最高的類別\n",
        "   - 轉換回 CPU 以便後續處理\n",
        "\n",
        "5. 結果展示\n",
        "   - 顯示原始句子、真實標籤、預測標籤\n",
        "   - 標記預測是否正確\n",
        "   - 計算準確率\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize 測試句子\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
        "outputs = model(**test_encodings)\n",
        "\n",
        "# 取得預測結果\n",
        "preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()  # 將結果轉回 CPU 以便處理\n",
        "\n",
        "# 顯示預測結果\n",
        "predicted_labels = [label_map[pred] for pred in preds]\n",
        "true_labels_text = [label_map[label] for label in true_labels]\n",
        "\n",
        "# 計算準確率\n",
        "correct = sum([1 for true, pred in zip(true_labels_text, predicted_labels) if true == pred])\n",
        "accuracy = correct / len(test_texts) * 100\n",
        "\n",
        "print(f\"你選擇的 {len(test_texts)} 個句子的預測結果：\\n\")\n",
        "\n",
        "for i, (idx, text, true_label, pred_label) in enumerate(zip(test_indices, test_texts, true_labels_text, predicted_labels)):\n",
        "    correct_mark = \"✓ 正確\" if true_label == pred_label else \"✗ 錯誤\"\n",
        "    # 只挑顯示錯誤的，準備作業3\n",
        "    if (true_label != pred_label):\n",
        "      print(f\"{i+1}. 測試集索引 [{idx}]\")\n",
        "      print(f\"   句子：{text}\")\n",
        "      print(f\"   真實標籤：{true_label}\")\n",
        "      print(f\"   預測標籤：{pred_label}\")\n",
        "      print(f\"   結果：{correct_mark}\\n\")\n",
        "\n",
        "print(f\"準確率：{correct}/{len(test_texts)} = {accuracy:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}